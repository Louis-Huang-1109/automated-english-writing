{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22242e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import levene\n",
    "from scipy.stats import f_oneway\n",
    "#Create samples\n",
    "df = pd.read_excel(\"Lexical Complexity.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6568fcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in enumerate(df.columns):\n",
    "    a1 = [df[j][i] for  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1be65e96",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Maas_TTR'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Maas_TTR'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 433\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m    432\u001b[0m     cefr \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCEFR\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 433\u001b[0m     maas_ttr \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaas_TTR\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cefr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    435\u001b[0m         a1_maas_ttr\u001b[38;5;241m.\u001b[39mappend(maas_ttr)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1004\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1007\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_value(key)\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1012\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:1116\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1116\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_loc(label)\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Maas_TTR'"
     ]
    }
   ],
   "source": [
    "# lexical density\n",
    "\n",
    "a1_lexical_density = []\n",
    "a2_lexical_density = []\n",
    "b1_lexical_density = []\n",
    "b2_lexical_density = []\n",
    "c1_lexical_density = []\n",
    "for index, row in df.iterrows():\n",
    "    cefr = row[\"CEFR\"]\n",
    "    density = row[\"Lexical Density\"]\n",
    "    if cefr == \"A1\":\n",
    "        a1_lexical_density.append(density)\n",
    "    elif cefr == \"A2\":\n",
    "        a2_lexical_density.append(density)\n",
    "    elif cefr == \"B1\":\n",
    "        b1_lexical_density.append(density)\n",
    "    elif cefr == \"B2\":\n",
    "        b2_lexical_density.append(density)\n",
    "    elif cefr == \"C1\":\n",
    "        c1_lexical_density.append(density)\n",
    "        \n",
    "#lexical sophistication_I\n",
    "a1_lexical_sophistication_I = []\n",
    "a2_lexical_sophistication_I = []\n",
    "b1_lexical_sophistication_I = []\n",
    "b2_lexical_sophistication_I = []\n",
    "c1_lexical_sophistication_I = []\n",
    "for index, row in df.iterrows():\n",
    "    cefr = row[\"CEFR\"]\n",
    "    sophistication = row[\"Lexical Sophistication-I\"]\n",
    "    if cefr == \"A1\":\n",
    "        a1_lexical_sophistication_I.append(sophistication)\n",
    "    elif cefr == \"A2\":\n",
    "        a2_lexical_sophistication_I.append(sophistication)\n",
    "    elif cefr == \"B1\":\n",
    "        b1_lexical_sophistication_I.append(sophistication)\n",
    "    elif cefr == \"B2\":\n",
    "        b2_lexical_sophistication_I.append(sophistication)\n",
    "    elif cefr == \"C1\":\n",
    "        c1_lexical_sophistication_I.append(sophistication)\n",
    "\n",
    "#lexical sophistication_II\n",
    "a1_lexical_sophistication_II = []\n",
    "a2_lexical_sophistication_II = []\n",
    "b1_lexical_sophistication_II = []\n",
    "b2_lexical_sophistication_II = []\n",
    "c1_lexical_sophistication_II = []\n",
    "for index, row in df.iterrows():\n",
    "    cefr = row[\"CEFR\"]\n",
    "    sophistication = row[\"Lexical Sophistication-II\"]\n",
    "    if cefr == \"A1\":\n",
    "        a1_lexical_sophistication_II.append(sophistication)\n",
    "    elif cefr == \"A2\":\n",
    "        a2_lexical_sophistication_II.append(sophistication)\n",
    "    elif cefr == \"B1\":\n",
    "        b1_lexical_sophistication_II.append(sophistication)\n",
    "    elif cefr == \"B2\":\n",
    "        b2_lexical_sophistication_II.append(sophistication)\n",
    "    elif cefr == \"C1\":\n",
    "        c1_lexical_sophistication_II.append(sophistication)\n",
    "\n",
    "\n",
    "# verb_sophistication_I\n",
    "a1_verb_sophistication_I = []\n",
    "a2_verb_sophistication_I = []\n",
    "b1_verb_sophistication_I = []\n",
    "b2_verb_sophistication_I = []\n",
    "c1_verb_sophistication_I = []\n",
    "for index, row in df.iterrows():\n",
    "    cefr = row[\"CEFR\"]\n",
    "    sophistication = row[\"Verb Sophistication-II\"]\n",
    "    if cefr == \"A1\":\n",
    "        a1_verb_sophistication_I.append(sophistication)\n",
    "    elif cefr == \"A2\":\n",
    "        a2_verb_sophistication_I.append(sophistication)\n",
    "    elif cefr == \"B1\":\n",
    "        b1_verb_sophistication_I.append(sophistication)\n",
    "    elif cefr == \"B2\":\n",
    "        b2_verb_sophistication_I.append(sophistication)\n",
    "    elif cefr == \"C1\":\n",
    "        c1_verb_sophistication_I.append(sophistication)\n",
    "\n",
    "    \n",
    "# corrected_vs1\n",
    "a1_corrected_vs1 = []\n",
    "a2_corrected_vs1 = []\n",
    "b1_corrected_vs1 = []\n",
    "b2_corrected_vs1 = []\n",
    "c1_corrected_vs1 = []\n",
    "for index, row in df.iterrows():\n",
    "    cefr = row[\"CEFR\"]\n",
    "    ratio = row[\"Corrected VS1\"]\n",
    "    if cefr == \"A1\":\n",
    "        a1_corrected_vs1.append(ratio)\n",
    "    elif cefr == \"A2\":\n",
    "        a2_corrected_vs1.append(ratio)\n",
    "    elif cefr == \"B1\":\n",
    "        b1_corrected_vs1.append(ratio)\n",
    "    elif cefr == \"B2\":\n",
    "        b2_corrected_vs1.append(ratio)\n",
    "    elif cefr == \"C1\":\n",
    "        c1_corrected_vs1.append(ratio)\n",
    "\n",
    "# verb_sophistication_II\n",
    "a1_verb_sophistication_II = []\n",
    "a2_verb_sophistication_II = []\n",
    "b1_verb_sophistication_II = []\n",
    "b2_verb_sophistication_II = []\n",
    "c1_verb_sophistication_II = []\n",
    "for index, row in df.iterrows():\n",
    "    cefr = row[\"CEFR\"]\n",
    "    sophistication = row[\"Verb Sophistication-II\"]\n",
    "    if cefr == \"A1\":\n",
    "        a1_verb_sophistication_II.append(sophistication)\n",
    "    elif cefr == \"A2\":\n",
    "        a2_verb_sophistication_II.append(sophistication)\n",
    "    elif cefr == \"B1\":\n",
    "        b1_verb_sophistication_II.append(sophistication)\n",
    "    elif cefr == \"B2\":\n",
    "        b2_verb_sophistication_II.append(sophistication)\n",
    "    elif cefr == \"C1\":\n",
    "        c1_verb_sophistication_II.append(sophistication)\n",
    "        \n",
    "# type token ratio\n",
    "a1_ttr = []\n",
    "a2_ttr = []\n",
    "b1_ttr = []\n",
    "b2_ttr = []\n",
    "c1_ttr = []\n",
    "for index, row in df.iterrows():\n",
    "    cefr = row[\"CEFR\"]\n",
    "    ttr = row[\"Type–Token Ratio\"]\n",
    "    if cefr == \"A1\":\n",
    "        a1_ttr.append(ttr)\n",
    "    elif cefr == \"A2\":\n",
    "        a2_ttr.append(ttr)\n",
    "    elif cefr == \"B1\":\n",
    "        b1_ttr.append(ttr)\n",
    "    elif cefr == \"B2\":\n",
    "        b2_ttr.append(ttr)\n",
    "    elif cefr == \"C1\":\n",
    "        c1_ttr.append(ttr)        \n",
    "        \n",
    "# number_of_different_words\n",
    "a1_number_of_different_words = []\n",
    "a2_number_of_different_words = []\n",
    "b1_number_of_different_words = []\n",
    "b2_number_of_different_words = []\n",
    "c1_number_of_different_words = []\n",
    "for index, row in df.iterrows():\n",
    "    cefr = row[\"CEFR\"]\n",
    "    num_words = row[\"Number of Different Words\"]\n",
    "    if cefr == \"A1\":\n",
    "        a1_number_of_different_words.append(num_words)\n",
    "    elif cefr == \"A2\":\n",
    "        a2_number_of_different_words.append(num_words)\n",
    "    elif cefr == \"B1\":\n",
    "        b1_number_of_different_words.append(num_words)\n",
    "    elif cefr == \"B2\":\n",
    "        b2_number_of_different_words.append(num_words)\n",
    "    elif cefr == \"C1\":\n",
    "        c1_number_of_different_words.append(num_words)\n",
    "\n",
    "# corrected_ttr\n",
    "a1_corrected_ttr = []\n",
    "a2_corrected_ttr = []\n",
    "b1_corrected_ttr = []\n",
    "b2_corrected_ttr = []\n",
    "c1_corrected_ttr = []\n",
    "for index, row in df.iterrows():\n",
    "    cefr = row[\"CEFR\"]\n",
    "    ttr = row[\"Corrected TTR\"]\n",
    "    if cefr == \"A1\":\n",
    "        a1_corrected_ttr.append(ttr)\n",
    "    elif cefr == \"A2\":\n",
    "        a2_corrected_ttr.append(ttr)\n",
    "    elif cefr == \"B1\":\n",
    "        b1_corrected_ttr.append(ttr)\n",
    "    elif cefr == \"B2\":\n",
    "        b2_corrected_ttr.append(ttr)\n",
    "    elif cefr == \"C1\":\n",
    "        c1_corrected_ttr.append(ttr)\n",
    "\n",
    "# root_ttr \n",
    "a1_root_ttr = []\n",
    "a2_root_ttr = []\n",
    "b1_root_ttr = []\n",
    "b2_root_ttr = []\n",
    "c1_root_ttr = []\n",
    "for index, row in df.iterrows():\n",
    "    cefr = row[\"CEFR\"]\n",
    "    root_ttr = row[\"Root TTR\"]\n",
    "    if cefr == \"A1\":\n",
    "        a1_root_ttr.append(root_ttr)\n",
    "    elif cefr == \"A2\":\n",
    "        a2_root_ttr.append(root_ttr)\n",
    "    elif cefr == \"B1\":\n",
    "        b1_root_ttr.append(root_ttr)\n",
    "    elif cefr == \"B2\":\n",
    "        b2_root_ttr.append(root_ttr)\n",
    "    elif cefr == \"C1\":\n",
    "        c1_root_ttr.append(root_ttr)\n",
    "        \n",
    "#bilogarithmic_ttr        \n",
    "a1_bilogarithmic_ttr = []\n",
    "a2_bilogarithmic_ttr = []\n",
    "b1_bilogarithmic_ttr = []\n",
    "b2_bilogarithmic_ttr = []\n",
    "c1_bilogarithmic_ttr = []\n",
    "for index, row in df.iterrows():\n",
    "    cefr = row[\"CEFR\"]\n",
    "    root_ttr = row[\"Bilogarithmic TTR\"]\n",
    "    if cefr == \"A1\":\n",
    "        a1_bilogarithmic_ttr.append(root_ttr)\n",
    "    elif cefr == \"A2\":\n",
    "        a2_bilogarithmic_ttr.append(root_ttr)\n",
    "    elif cefr == \"B1\":\n",
    "        b1_bilogarithmic_ttr.append(root_ttr)\n",
    "    elif cefr == \"B2\":\n",
    "        b2_bilogarithmic_ttr.append(root_ttr)\n",
    "    elif cefr == \"C1\":\n",
    "        c1_bilogarithmic_ttr.append(root_ttr)\n",
    "        \n",
    "# uber_index\n",
    "a1_uber_index = []\n",
    "a2_uber_index = []\n",
    "b1_uber_index = []\n",
    "b2_uber_index = []\n",
    "c1_uber_index = []\n",
    "for index, row in df.iterrows():\n",
    "    cefr = row[\"CEFR\"]\n",
    "    uber_index = row[\"Uber Index\"]\n",
    "    if cefr == \"A1\":\n",
    "        a1_uber_index.append(uber_index)\n",
    "    elif cefr == \"A2\":\n",
    "        a2_uber_index.append(uber_index)\n",
    "    elif cefr == \"B1\":\n",
    "        b1_uber_index.append(uber_index)\n",
    "    elif cefr == \"B2\":\n",
    "        b2_uber_index.append(uber_index)\n",
    "    elif cefr == \"C1\":\n",
    "        c1_uber_index.append(uber_index)\n",
    "\n",
    "# lexical_word_variation\n",
    "a1_lexical_word_variation = []\n",
    "a2_lexical_word_variation = []\n",
    "b1_lexical_word_variation = []\n",
    "b2_lexical_word_variation = []\n",
    "c1_lexical_word_variation = []\n",
    "for index, row in df.iterrows():\n",
    "    cefr = row[\"CEFR\"]\n",
    "    word_variation = row[\"Lexical Word Variation\"]\n",
    "    if cefr == \"A1\":\n",
    "        a1_lexical_word_variation.append(word_variation)\n",
    "    elif cefr == \"A2\":\n",
    "        a2_lexical_word_variation.append(word_variation)\n",
    "    elif cefr == \"B1\":\n",
    "        b1_lexical_word_variation.append(word_variation)\n",
    "    elif cefr == \"B2\":\n",
    "        b2_lexical_word_variation.append(word_variation)\n",
    "    elif cefr == \"C1\":\n",
    "        c1_lexical_word_variation.append(word_variation)\n",
    "\n",
    "# verb_variation_I\n",
    "a1_verb_variation_I = []\n",
    "a2_verb_variation_I = []\n",
    "b1_verb_variation_I = []\n",
    "b2_verb_variation_I = []\n",
    "c1_verb_variation_I = []\n",
    "for index, row in df.iterrows():\n",
    "    cefr = row[\"CEFR\"]\n",
    "    verb_variation = row[\"Verb Variation-I\"]\n",
    "    if cefr == \"A1\":\n",
    "        a1_verb_variation_I.append(verb_variation)\n",
    "    elif cefr == \"A2\":\n",
    "        a2_verb_variation_I.append(verb_variation)\n",
    "    elif cefr == \"B1\":\n",
    "        b1_verb_variation_I.append(verb_variation)\n",
    "    elif cefr == \"B2\":\n",
    "        b2_verb_variation_I.append(verb_variation)\n",
    "    elif cefr == \"C1\":\n",
    "        c1_verb_variation_I.append(verb_variation)\n",
    "\n",
    "# squared_vv1\n",
    "a1_squared_vv1 = []\n",
    "a2_squared_vv1 = []\n",
    "b1_squared_vv1 = []\n",
    "b2_squared_vv1 = []\n",
    "c1_squared_vv1 = []\n",
    "for index, row in df.iterrows():\n",
    "    cefr = row[\"CEFR\"]\n",
    "    squared_vv1 = row[\"Squared VV1\"]\n",
    "    if cefr == \"A1\":\n",
    "        a1_squared_vv1.append(squared_vv1)\n",
    "    elif cefr == \"A2\":\n",
    "        a2_squared_vv1.append(squared_vv1)\n",
    "    elif cefr == \"B1\":\n",
    "        b1_squared_vv1.append(squared_vv1)\n",
    "    elif cefr == \"B2\":\n",
    "        b2_squared_vv1.append(squared_vv1)\n",
    "    elif cefr == \"C1\":\n",
    "        c1_squared_vv1.append(squared_vv1)\n",
    "        \n",
    "# corrected_vv1\n",
    "a1_corrected_vv1 = []\n",
    "a2_corrected_vv1 = []\n",
    "b1_corrected_vv1 = []\n",
    "b2_corrected_vv1 = []\n",
    "c1_corrected_vv1 = []\n",
    "for index, row in df.iterrows():\n",
    "    cefr = row[\"CEFR\"]\n",
    "    corrected_vv1 = row[\"Corrected VV1\"]\n",
    "    if cefr == \"A1\":\n",
    "        a1_corrected_vv1.append(corrected_vv1)\n",
    "    elif cefr == \"A2\":\n",
    "        a2_corrected_vv1.append(corrected_vv1)\n",
    "    elif cefr == \"B1\":\n",
    "        b1_corrected_vv1.append(corrected_vv1)\n",
    "    elif cefr == \"B2\":\n",
    "        b2_corrected_vv1.append(corrected_vv1)\n",
    "    elif cefr == \"C1\":\n",
    "        c1_corrected_vv1.append(corrected_vv1)\n",
    "\n",
    "        \n",
    "# verb_variation_II\n",
    "a1_verb_variation_II = []\n",
    "a2_verb_variation_II = []\n",
    "b1_verb_variation_II = []\n",
    "b2_verb_variation_II = []\n",
    "c1_verb_variation_II = []\n",
    "for index, row in df.iterrows():\n",
    "    cefr = row[\"CEFR\"]\n",
    "    verb_variation = row[\"Verb Variation-II\"]\n",
    "    if cefr == \"A1\":\n",
    "        a1_verb_variation_II.append(verb_variation)\n",
    "    elif cefr == \"A2\":\n",
    "        a2_verb_variation_II.append(verb_variation)\n",
    "    elif cefr == \"B1\":\n",
    "        b1_verb_variation_II.append(verb_variation)\n",
    "    elif cefr == \"B2\":\n",
    "        b2_verb_variation_II.append(verb_variation)\n",
    "    elif cefr == \"C1\":\n",
    "        c1_verb_variation_II.append(verb_variation)\n",
    "\n",
    "# noun_variation\n",
    "a1_noun_variation = []\n",
    "a2_noun_variation = []\n",
    "b1_noun_variation = []\n",
    "b2_noun_variation = []\n",
    "c1_noun_variation = []\n",
    "for index, row in df.iterrows():\n",
    "    cefr = row[\"CEFR\"]\n",
    "    noun_variation = row[\"Noun Variation\"]\n",
    "    if cefr == \"A1\":\n",
    "        a1_noun_variation.append(noun_variation)\n",
    "    elif cefr == \"A2\":\n",
    "        a2_noun_variation.append(noun_variation)\n",
    "    elif cefr == \"B1\":\n",
    "        b1_noun_variation.append(noun_variation)\n",
    "    elif cefr == \"B2\":\n",
    "        b2_noun_variation.append(noun_variation)\n",
    "    elif cefr == \"C1\":\n",
    "        c1_noun_variation.append(noun_variation)\n",
    "\n",
    "# adjective_variation\n",
    "a1_adjective_variation = []\n",
    "a2_adjective_variation = []\n",
    "b1_adjective_variation = []\n",
    "b2_adjective_variation = []\n",
    "c1_adjective_variation = []\n",
    "for index, row in df.iterrows():\n",
    "    cefr = row[\"CEFR\"]\n",
    "    adjective_variation = row[\"Adjective Variation\"]\n",
    "    if cefr == \"A1\":\n",
    "        a1_adjective_variation.append(adjective_variation)\n",
    "    elif cefr == \"A2\":\n",
    "        a2_adjective_variation.append(adjective_variation)\n",
    "    elif cefr == \"B1\":\n",
    "        b1_adjective_variation.append(adjective_variation)\n",
    "    elif cefr == \"B2\":\n",
    "        b2_adjective_variation.append(adjective_variation)\n",
    "    elif cefr == \"C1\":\n",
    "        c1_adjective_variation.append(adjective_variation)\n",
    "\n",
    "# adverb_variation\n",
    "a1_adverb_variation = []\n",
    "a2_adverb_variation = []\n",
    "b1_adverb_variation = []\n",
    "b2_adverb_variation = []\n",
    "c1_adverb_variation = []\n",
    "for index, row in df.iterrows():\n",
    "    cefr = row[\"CEFR\"]\n",
    "    adverb_variation = row[\"Adverb Variation\"]\n",
    "    if cefr == \"A1\":\n",
    "        a1_adverb_variation.append(adverb_variation)\n",
    "    elif cefr == \"A2\":\n",
    "        a2_adverb_variation.append(adverb_variation)\n",
    "    elif cefr == \"B1\":\n",
    "        b1_adverb_variation.append(adverb_variation)\n",
    "    elif cefr == \"B2\":\n",
    "        b2_adverb_variation.append(adverb_variation)\n",
    "    elif cefr == \"C1\":\n",
    "        c1_adverb_variation.append(adverb_variation)\n",
    "\n",
    "# modifier_variation\n",
    "a1_modifier_variation = []\n",
    "a2_modifier_variation = []\n",
    "b1_modifier_variation = []\n",
    "b2_modifier_variation = []\n",
    "c1_modifier_variation = []\n",
    "for index, row in df.iterrows():\n",
    "    cefr = row[\"CEFR\"]\n",
    "    modifier_variation = row[\"Modifier Variation\"]\n",
    "    if cefr == \"A1\":\n",
    "        a1_modifier_variation.append(modifier_variation)\n",
    "    elif cefr == \"A2\":\n",
    "        a2_modifier_variation.append(modifier_variation)\n",
    "    elif cefr == \"B1\":\n",
    "        b1_modifier_variation.append(modifier_variation)\n",
    "    elif cefr == \"B2\":\n",
    "        b2_modifier_variation.append(modifier_variation)\n",
    "    elif cefr == \"C1\":\n",
    "        c1_modifier_variation.append(modifier_variation)\n",
    "\n",
    "# maas_ttr\n",
    "a1_maas_ttr = []\n",
    "a2_maas_ttr = []\n",
    "b1_maas_ttr = []\n",
    "b2_maas_ttr = []\n",
    "c1_maas_ttr = []\n",
    "for index, row in df.iterrows():\n",
    "    cefr = row[\"CEFR\"]\n",
    "    maas_ttr = row[\"Maas_TTR\"]\n",
    "    if cefr == \"A1\":\n",
    "        a1_maas_ttr.append(maas_ttr)\n",
    "    elif cefr == \"A2\":\n",
    "        a2_maas_ttr.append(maas_ttr)\n",
    "    elif cefr == \"B1\":\n",
    "        b1_maas_ttr.append(maas_ttr)\n",
    "    elif cefr == \"B2\":\n",
    "        b2_maas_ttr.append(maas_ttr)\n",
    "    elif cefr == \"C1\":\n",
    "        c1_maas_ttr.append(maas_ttr)\n",
    "\n",
    "# hdd\n",
    "a1_hdd = []\n",
    "a2_hdd = []\n",
    "b1_hdd = []\n",
    "b2_hdd = []\n",
    "c1_hdd = []\n",
    "for index, row in df.iterrows():\n",
    "    cefr = row[\"CEFR\"]\n",
    "    hdd = row[\"HDD\"]\n",
    "    if cefr == \"A1\":\n",
    "        a1_hdd.append(hdd)\n",
    "    elif cefr == \"A2\":\n",
    "        a2_hdd.append(hdd)\n",
    "    elif cefr == \"B1\":\n",
    "        b1_hdd.append(hdd)\n",
    "    elif cefr == \"B2\":\n",
    "        b2_hdd.append(hdd)\n",
    "    elif cefr == \"C1\":\n",
    "        c1_hdd.append(hdd)\n",
    "\n",
    "# mtld\n",
    "a1_mtld = []\n",
    "a2_mtld = []\n",
    "b1_mtld = []\n",
    "b2_mtld = []\n",
    "c1_mtld = []\n",
    "for index, row in df.iterrows():\n",
    "    cefr = row[\"CEFR\"]\n",
    "    mtld = row[\"MTLD\"]\n",
    "    if cefr == \"A1\":\n",
    "        a1_mtld.append(mtld)\n",
    "    elif cefr == \"A2\":\n",
    "        a2_mtld.append(mtld)\n",
    "    elif cefr == \"B1\":\n",
    "        b1_mtld.append(mtld)\n",
    "    elif cefr == \"B2\":\n",
    "        b2_mtld.append(mtld)\n",
    "    elif cefr == \"C1\":\n",
    "        c1_mtld.append(mtld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c57fbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191663\n",
      "129591\n",
      "61506\n",
      "18187\n",
      "5115\n"
     ]
    }
   ],
   "source": [
    "print(len(a1_lexical_density))\n",
    "print(len(a2_lexical_density))\n",
    "print(len(b1_lexical_density))\n",
    "print(len(b2_lexical_density))\n",
    "print(len(c1_lexical_density))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49aabd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LD_statistic: 31.20358690418169\n",
      "LD_p_value: 5.0475479217707675e-26\n",
      "LS1_statistic: 10813.568101188199\n",
      "LS1_p_value: 0.0\n",
      "LS2_statistic: 13847.361263391835\n",
      "LS2_p_value: 0.0\n",
      "VS1_statistic: 22355.09051116115\n",
      "VS1_p_value: 0.0\n",
      "Corrected_vs1 statistic: 29383.854764226387\n",
      "Corrected_vs1 p-value: 0.0\n",
      "Verb_sophistication_II statistic: 22355.09051116115\n",
      "Verb_sophistication_II p-value: 0.0\n",
      "Number_of_different_words statistic: 278667.29698785633\n",
      "Number_of_different_words p-value: 0.0\n",
      "TTR_statistic: 25760.797385090602\n",
      "TTR_p_value: 0.0\n",
      "Corrected_ttr statistic: 170085.80250563097\n",
      "Corrected_ttr p-value: 0.0\n",
      "Root_ttr statistic: 170085.80250563085\n",
      "Root_ttr p-value: 0.0\n",
      "Bilogarithmic_ttr statistic: 9763.033902672685\n",
      "Bilogarithmic_ttr p-value: 0.0\n",
      "Uber_index statistic: 8308.442772405582\n",
      "Uber_index p-value: 0.0\n",
      "Lexical_word_variation statistic: 5042.4836439315695\n",
      "Lexical_word_variation p-value: 0.0\n",
      "Verb_variation_I statistic: 400.1027412539071\n",
      "Verb_variation_I p-value: 0.0\n",
      "squared_vv1 statistic: 101747.573009973\n",
      "squared_vv1 p-value: 0.0\n",
      "corrected_vv1 statistic: 88809.43929862298\n",
      "corrected_vv1 p-value: 0.0\n",
      "Verb_variation_II statistic: 5400.493413094094\n",
      "Verb_variation_II p-value: 0.0\n",
      "Noun_variation statistic: 21280.368949724885\n",
      "Noun_variation p-value: 0.0\n",
      "Adjective_variation statistic: 1317.3131066314243\n",
      "Adjective_variation p-value: 0.0\n",
      "Adverb_variation statistic: 15139.953192095412\n",
      "Adverb_variation p-value: 0.0\n",
      "Modifier_variation statistic: 3656.492470604266\n",
      "Modifier_variation p-value: 0.0\n",
      "Maas_ttr statistic: 7308.241677006378\n",
      "Maas_ttr p-value: 0.0\n",
      "HDD statistic: 46623.616091533404\n",
      "Hdd p-value: 0.0\n",
      "MTLD statistic: 27241.29678232604\n",
      "MTLD p-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "#ld anova\n",
    "ld_statistic, ld_p_value=f_oneway(a1_lexical_density,a2_lexical_density,b1_lexical_density,b2_lexical_density,c1_lexical_density)\n",
    "print('LD_statistic:',ld_statistic)\n",
    "print('LD_p_value:',ld_p_value)\n",
    "\n",
    "#ls1 anova\n",
    "ls1_statistic, ls1_p_value=f_oneway(a1_lexical_sophistication_I,a2_lexical_sophistication_I,b1_lexical_sophistication_I,b2_lexical_sophistication_I,c1_lexical_sophistication_I)\n",
    "print('LS1_statistic:',ls1_statistic)\n",
    "print('LS1_p_value:',ls1_p_value)\n",
    "\n",
    "#ls2 anova\n",
    "ls2_statistic, ls2_p_value=f_oneway(a1_lexical_sophistication_II,a2_lexical_sophistication_II,b1_lexical_sophistication_II,b2_lexical_sophistication_II,c1_lexical_sophistication_II)\n",
    "print('LS2_statistic:',ls2_statistic)\n",
    "print('LS2_p_value:',ls2_p_value)\n",
    "\n",
    "#vs1 anova\n",
    "vs1_statistic, vs1_p_value=f_oneway(a1_verb_sophistication_I,a2_verb_sophistication_I,b1_verb_sophistication_I,b2_verb_sophistication_I,c1_verb_sophistication_I)\n",
    "print('VS1_statistic:',vs1_statistic)\n",
    "print('VS1_p_value:',vs1_p_value)\n",
    "\n",
    "# corrected_vs1 ANOVA\n",
    "corrected_vs1_statistic, corrected_vs1_p_value = f_oneway(a1_corrected_vs1, a2_corrected_vs1, b1_corrected_vs1, b2_corrected_vs1, c1_corrected_vs1)\n",
    "print('Corrected_vs1 statistic:', corrected_vs1_statistic)\n",
    "print('Corrected_vs1 p-value:', corrected_vs1_p_value)\n",
    "\n",
    "# verb_sophistication_II ANOVA\n",
    "verb_sophistication_II_statistic, verb_sophistication_II_p_value = f_oneway(a1_verb_sophistication_II, a2_verb_sophistication_II, b1_verb_sophistication_II, b2_verb_sophistication_II, c1_verb_sophistication_II)\n",
    "print('Verb_sophistication_II statistic:', verb_sophistication_II_statistic)\n",
    "print('Verb_sophistication_II p-value:', verb_sophistication_II_p_value)\n",
    "\n",
    "# number_of_different_words ANOVA\n",
    "number_of_different_words_statistic, number_of_different_words_p_value = f_oneway(a1_number_of_different_words, a2_number_of_different_words, b1_number_of_different_words, b2_number_of_different_words, c1_number_of_different_words)\n",
    "print('Number_of_different_words statistic:', number_of_different_words_statistic)\n",
    "print('Number_of_different_words p-value:', number_of_different_words_p_value)\n",
    "\n",
    "# type token ratio ANOVA\n",
    "ttr_statistic, ttr_p_value=f_oneway(a1_ttr,a2_ttr,b1_ttr,b2_ttr,c1_ttr)\n",
    "print('TTR_statistic:',ttr_statistic)\n",
    "print('TTR_p_value:',ttr_p_value)\n",
    "\n",
    "# corrected_ttr ANOVA\n",
    "corrected_ttr_statistic, corrected_ttr_p_value = f_oneway(a1_corrected_ttr, a2_corrected_ttr, b1_corrected_ttr, b2_corrected_ttr, c1_corrected_ttr)\n",
    "print('Corrected_ttr statistic:', corrected_ttr_statistic)\n",
    "print('Corrected_ttr p-value:', corrected_ttr_p_value)\n",
    "\n",
    "# root_ttr ANOVA\n",
    "root_ttr_statistic, root_ttr_p_value = f_oneway(a1_root_ttr, a2_root_ttr, b1_root_ttr, b2_root_ttr, c1_root_ttr)\n",
    "print('Root_ttr statistic:', root_ttr_statistic)\n",
    "print('Root_ttr p-value:', root_ttr_p_value)\n",
    "\n",
    "# bilogarithmic_ttr ANOVA\n",
    "bilogarithmic_ttr_statistic, bilogarithmic_ttr_p_value = f_oneway(a1_bilogarithmic_ttr, a2_bilogarithmic_ttr, b1_bilogarithmic_ttr, b2_bilogarithmic_ttr, c1_bilogarithmic_ttr)\n",
    "print('Bilogarithmic_ttr statistic:', bilogarithmic_ttr_statistic)\n",
    "print('Bilogarithmic_ttr p-value:', bilogarithmic_ttr_p_value)\n",
    "\n",
    "# uber_index ANOVA\n",
    "uber_index_statistic, uber_index_p_value = f_oneway(a1_uber_index, a2_uber_index, b1_uber_index, b2_uber_index, c1_uber_index)\n",
    "print('Uber_index statistic:', uber_index_statistic)\n",
    "print('Uber_index p-value:', uber_index_p_value)\n",
    "\n",
    "# lexical_word_variation ANOVA\n",
    "lexical_word_variation_statistic, lexical_word_variation_p_value = f_oneway(a1_lexical_word_variation, a2_lexical_word_variation, b1_lexical_word_variation, b2_lexical_word_variation, c1_lexical_word_variation)\n",
    "print('Lexical_word_variation statistic:', lexical_word_variation_statistic)\n",
    "print('Lexical_word_variation p-value:', lexical_word_variation_p_value)\n",
    "\n",
    "# verb_variation_I ANOVA\n",
    "verb_variation_I_statistic, verb_variation_I_p_value = f_oneway(a1_verb_variation_I, a2_verb_variation_I, b1_verb_variation_I, b2_verb_variation_I, c1_verb_variation_I)\n",
    "print('Verb_variation_I statistic:', verb_variation_I_statistic)\n",
    "print('Verb_variation_I p-value:', verb_variation_I_p_value)\n",
    "\n",
    "# squared_vv1 ANOVA\n",
    "squared_vv1_statistic, squared_vv1_p_value = f_oneway(a1_squared_vv1, a2_squared_vv1, b1_squared_vv1, b2_squared_vv1, c1_squared_vv1)\n",
    "print('squared_vv1 statistic:', squared_vv1_statistic)\n",
    "print('squared_vv1 p-value:', squared_vv1_p_value)\n",
    "\n",
    "# corrected_vv1 ANOVA\n",
    "corrected_vv1_statistic, corrected_vv1_p_value = f_oneway(a1_corrected_vv1, a2_corrected_vv1, b1_corrected_vv1, b2_corrected_vv1, c1_corrected_vv1)\n",
    "print('corrected_vv1 statistic:', corrected_vv1_statistic)\n",
    "print('corrected_vv1 p-value:', corrected_vv1_p_value)\n",
    "\n",
    "# verb_variation_II ANOVA\n",
    "verb_variation_II_statistic, verb_variation_II_p_value = f_oneway(a1_verb_variation_II, a2_verb_variation_II, b1_verb_variation_II, b2_verb_variation_II, c1_verb_variation_II)\n",
    "print('Verb_variation_II statistic:', verb_variation_II_statistic)\n",
    "print('Verb_variation_II p-value:', verb_variation_II_p_value)\n",
    "\n",
    "# noun_variation ANOVA\n",
    "noun_variation_statistic, noun_variation_p_value = f_oneway(a1_noun_variation, a2_noun_variation, b1_noun_variation, b2_noun_variation, c1_noun_variation)\n",
    "print('Noun_variation statistic:', noun_variation_statistic)\n",
    "print('Noun_variation p-value:', noun_variation_p_value)\n",
    "\n",
    "# adjective_variation ANOVA\n",
    "adjective_variation_statistic, adjective_variation_p_value = f_oneway(a1_adjective_variation, a2_adjective_variation, b1_adjective_variation, b2_adjective_variation, c1_adjective_variation)\n",
    "print('Adjective_variation statistic:', adjective_variation_statistic)\n",
    "print('Adjective_variation p-value:', adjective_variation_p_value)\n",
    "\n",
    "# adverb_variation ANOVA\n",
    "adverb_variation_statistic, adverb_variation_p_value = f_oneway(a1_adverb_variation, a2_adverb_variation, b1_adverb_variation, b2_adverb_variation, c1_adverb_variation)\n",
    "print('Adverb_variation statistic:', adverb_variation_statistic)\n",
    "print('Adverb_variation p-value:', adverb_variation_p_value)\n",
    "\n",
    "# modifier_variation ANOVA\n",
    "modifier_variation_statistic, modifier_variation_p_value = f_oneway(a1_modifier_variation, a2_modifier_variation, b1_modifier_variation, b2_modifier_variation, c1_modifier_variation)\n",
    "print('Modifier_variation statistic:', modifier_variation_statistic)\n",
    "print('Modifier_variation p-value:', modifier_variation_p_value)\n",
    "\n",
    "# maas_ttr ANOVA\n",
    "maas_ttr_statistic, maas_ttr_p_value = f_oneway(a1_maas_ttr, a2_maas_ttr, b1_maas_ttr, b2_maas_ttr, c1_maas_ttr)\n",
    "print('Maas_ttr statistic:', maas_ttr_statistic)\n",
    "print('Maas_ttr p-value:', maas_ttr_p_value)\n",
    "\n",
    "# hdd ANOVA\n",
    "hdd_statistic, hdd_p_value = f_oneway(a1_hdd, a2_hdd, b1_hdd, b2_hdd, c1_hdd)\n",
    "print('HDD statistic:', hdd_statistic)\n",
    "print('Hdd p-value:', hdd_p_value)\n",
    "\n",
    "# mtld ANOVA\n",
    "mtld_statistic, mtld_p_value = f_oneway(a1_mtld, a2_mtld, b1_mtld, b2_mtld, c1_mtld)\n",
    "print('MTLD statistic:', mtld_statistic)\n",
    "print('MTLD p-value:', mtld_p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c89b428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c1c7b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"Statistic\": [\n",
    "        ld_statistic, ls1_statistic, ls2_statistic, vs1_statistic, corrected_vs1_statistic,\n",
    "        verb_sophistication_II_statistic, number_of_different_words_statistic, ttr_statistic,\n",
    "        corrected_ttr_statistic, root_ttr_statistic, bilogarithmic_ttr_statistic, uber_index_statistic,\n",
    "        lexical_word_variation_statistic, verb_variation_I_statistic, squared_vv1_statistic, corrected_vv1_statistic,\n",
    "        verb_variation_II_statistic, noun_variation_statistic, adjective_variation_statistic, adverb_variation_statistic,\n",
    "        modifier_variation_statistic, maas_ttr_statistic, hdd_statistic, mtld_statistic\n",
    "    ],\n",
    "    \"P-value\": [\n",
    "        ld_p_value, ls1_p_value, ls2_p_value, vs1_p_value, corrected_vs1_p_value,\n",
    "        verb_sophistication_II_p_value, number_of_different_words_p_value, ttr_p_value,\n",
    "        corrected_ttr_p_value, root_ttr_p_value, bilogarithmic_ttr_p_value, uber_index_p_value,\n",
    "        lexical_word_variation_p_value, verb_variation_I_p_value, squared_vv1_p_value, corrected_vv1_p_value,\n",
    "        verb_variation_II_p_value, noun_variation_p_value, adjective_variation_p_value, adverb_variation_p_value,\n",
    "        modifier_variation_p_value, maas_ttr_p_value, hdd_p_value, mtld_p_value\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "243889c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index 樣本 mean std \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Lexical Density\n",
    "nums_lexical_density = len(df[\"Lexical Density\"])\n",
    "means_lexical_density = np.mean(df[\"Lexical Density\"])\n",
    "std_lexical_density = np.std(df[\"Lexical Density\"])\n",
    "\n",
    "# Lexical Sophistication-I\n",
    "nums_lexical_sophistication_I = len(df[\"Lexical Sophistication-I\"])\n",
    "means_lexical_sophistication_I = np.mean(df[\"Lexical Sophistication-I\"])\n",
    "std_lexical_sophistication_I = np.std(df[\"Lexical Sophistication-I\"])\n",
    "\n",
    "# Lexical Sophistication-II\n",
    "nums_lexical_sophistication_II = len(df[\"Lexical Sophistication-II\"])\n",
    "means_lexical_sophistication_II = np.mean(df[\"Lexical Sophistication-II\"])\n",
    "std_lexical_sophistication_II = np.std(df[\"Lexical Sophistication-II\"])\n",
    "\n",
    "# Verb Sophistication-I\n",
    "nums_verb_sophistication_I = len(df[\"Verb Sophistication-I\"])\n",
    "means_verb_sophistication_I = np.mean(df[\"Verb Sophistication-I\"])\n",
    "std_verb_sophistication_I = np.std(df[\"Verb Sophistication-I\"])\n",
    "\n",
    "\n",
    "# Corrected VS1\n",
    "nums_corrected_vs1 = len(df[\"Corrected VS1\"])\n",
    "means_corrected_vs1 = np.mean(df[\"Corrected VS1\"])\n",
    "std_corrected_vs1 = np.std(df[\"Corrected VS1\"])\n",
    "\n",
    "# Verb Sophistication-II\n",
    "nums_verb_sophistication_II = len(df[\"Verb Sophistication-II\"])\n",
    "means_verb_sophistication_II = np.mean(df[\"Verb Sophistication-II\"])\n",
    "std_verb_sophistication_II = np.std(df[\"Verb Sophistication-II\"])\n",
    "\n",
    "# Number of Different Words\n",
    "nums_number_of_different_words = len(df[\"Number of Different Words\"])\n",
    "means_number_of_different_words = np.mean(df[\"Number of Different Words\"])\n",
    "std_number_of_different_words = np.std(df[\"Number of Different Words\"])\n",
    "\n",
    "# Type–Token Ratio\n",
    "nums_type_token_ratio = len(df[\"Type–Token Ratio\"])\n",
    "means_type_token_ratio = np.mean(df[\"Type–Token Ratio\"])\n",
    "std_type_token_ratio = np.std(df[\"Type–Token Ratio\"])\n",
    "\n",
    "# Corrected TTR\n",
    "nums_corrected_ttr = len(df[\"Corrected TTR\"])\n",
    "means_corrected_ttr = np.mean(df[\"Corrected TTR\"])\n",
    "std_corrected_ttr = np.std(df[\"Corrected TTR\"])\n",
    "\n",
    "# Root TTR\n",
    "nums_root_ttr = len(df[\"Root TTR\"])\n",
    "means_root_ttr = np.mean(df[\"Root TTR\"])\n",
    "std_root_ttr = np.std(df[\"Root TTR\"])\n",
    "\n",
    "# Bilogarithmic TTR\n",
    "nums_bilogarithmic_ttr = len(df[\"Bilogarithmic TTR\"])\n",
    "means_bilogarithmic_ttr = np.mean(df[\"Bilogarithmic TTR\"])\n",
    "std_bilogarithmic_ttr = np.std(df[\"Bilogarithmic TTR\"])\n",
    "\n",
    "# Uber Index\n",
    "nums_uber_index = len(df[\"Uber Index\"])\n",
    "means_uber_index = np.mean(df[\"Uber Index\"])\n",
    "std_uber_index = np.std(df[\"Uber Index\"])\n",
    "\n",
    "# Lexical Word Variation\n",
    "nums_lexical_word_variation = len(df[\"Lexical Word Variation\"])\n",
    "means_lexical_word_variation = np.mean(df[\"Lexical Word Variation\"])\n",
    "std_lexical_word_variation = np.std(df[\"Lexical Word Variation\"])\n",
    "\n",
    "# Verb Variation-I\n",
    "nums_verb_variation_I = len(df[\"Verb Variation-I\"])\n",
    "means_verb_variation_I = np.mean(df[\"Verb Variation-I\"])\n",
    "std_verb_variation_I = np.std(df[\"Verb Variation-I\"])\n",
    "\n",
    "# Squared VV1\n",
    "nums_squared_vv1 = len(df[\"Squared VV1\"])\n",
    "means_squared_vv1 = np.mean(df[\"Squared VV1\"])\n",
    "std_squared_vv1 = np.std(df[\"Squared VV1\"])\n",
    "\n",
    "# Corrected VV1\n",
    "nums_corrected_vv1 = len(df[\"Corrected VV1\"])\n",
    "means_corrected_vv1 = np.mean(df[\"Corrected VV1\"])\n",
    "std_corrected_vv1 = np.std(df[\"Corrected VV1\"])\n",
    "\n",
    "# Verb Variation-II\n",
    "nums_verb_variation_II = len(df[\"Verb Variation-II\"])\n",
    "means_verb_variation_II = np.mean(df[\"Verb Variation-II\"])\n",
    "std_verb_variation_II = np.std(df[\"Verb Variation-II\"])\n",
    "\n",
    "# Noun Variation\n",
    "nums_noun_variation = len(df[\"Noun Variation\"])\n",
    "means_noun_variation = np.mean(df[\"Noun Variation\"])\n",
    "std_noun_variation = np.std(df[\"Noun Variation\"])\n",
    "\n",
    "# Adjective Variation\n",
    "nums_adjective_variation = len(df[\"Adjective Variation\"])\n",
    "means_adjective_variation = np.mean(df[\"Adjective Variation\"])\n",
    "std_adjective_variation = np.std(df[\"Adjective Variation\"])\n",
    "\n",
    "# Adverb Variation\n",
    "nums_adverb_variation = len(df[\"Adverb Variation\"])\n",
    "means_adverb_variation = np.mean(df[\"Adverb Variation\"])\n",
    "std_adverb_variation = np.std(df[\"Adverb Variation\"])\n",
    "\n",
    "# Modifier Variation\n",
    "nums_modifier_variation = len(df[\"Modifier Variation\"])\n",
    "means_modifier_variation = np.mean(df[\"Modifier Variation\"])\n",
    "std_modifier_variation = np.std(df[\"Modifier Variation\"])\n",
    "\n",
    "# Maas_TTR\n",
    "nums_maas_ttr = len(df[\"Maas_TTR\"])\n",
    "means_maas_ttr = np.mean(df[\"Maas_TTR\"])\n",
    "std_maas_ttr = np.std(df[\"Maas_TTR\"])\n",
    "\n",
    "# HDD\n",
    "nums_hdd = len(df[\"HDD\"])\n",
    "means_hdd = np.mean(df[\"HDD\"])\n",
    "std_hdd = np.std(df[\"HDD\"])\n",
    "\n",
    "# MTLD\n",
    "nums_mtld = len(df[\"MTLD\"])\n",
    "means_mtld = np.mean(df[\"MTLD\"])\n",
    "std_mtld = np.std(df[\"MTLD\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c006bcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各個 CEFR level index 的樣本數(N)、平均數(Mean)、標準差(SD)\n",
    "\n",
    "# CEFR level 樣本數\n",
    "nums_a1 = len(a1_lexical_density)\n",
    "nums_a2 = len(a2_lexical_density)\n",
    "nums_b1 = len(b1_lexical_density)\n",
    "nums_b2 = len(b2_lexical_density)\n",
    "nums_c1 = len(c1_lexical_density)\n",
    "\n",
    "# lexical density index mean \n",
    "a1_ld_mean = np.mean(a1_lexical_density)\n",
    "a2_ld_mean = np.mean(a2_lexical_density)\n",
    "b1_ld_mean = np.mean(b1_lexical_density)\n",
    "b2_ld_mean = np.mean(b2_lexical_density)\n",
    "c1_ld_mean = np.mean(c1_lexical_density)\n",
    "ld_mean_list = [a1_ld_mean,a2_ld_mean,b1_ld_mean,b2_ld_mean,c1_ld_mean]\n",
    "\n",
    "\n",
    "#lexical density index std\n",
    "a1_ld_std = np.std(a1_lexical_density)\n",
    "a2_ld_std = np.std(a2_lexical_density)\n",
    "b1_ld_std = np.std(b1_lexical_density)\n",
    "b2_ld_std = np.std(b2_lexical_density)\n",
    "c1_ld_std = np.std(c1_lexical_density)\n",
    "ld_std_list = [a1_ld_std,a2_ld_std,b1_ld_std,b2_ld_std,c1_ld_std]\n",
    "\n",
    "\n",
    "# Lexical Sophistication-I mean\n",
    "a1_ls1_mean = np.mean(a1_corrected_vs1)\n",
    "a2_ls1_mean = np.mean(a2_corrected_vs1)\n",
    "b1_ls1_mean = np.mean(b1_corrected_vs1)\n",
    "b2_ls1_mean = np.mean(b2_corrected_vs1)\n",
    "c1_ls1_mean = np.mean(c1_corrected_vs1)\n",
    "ls1_mean_list = [a1_ls1_mean, a2_ls1_mean, b1_ls1_mean, b2_ls1_mean, c1_ls1_mean]\n",
    "\n",
    "# Lexical Sophistication-I std\n",
    "a1_ls1_std = np.std(a1_corrected_vs1)\n",
    "a2_ls1_std = np.std(a2_corrected_vs1)\n",
    "b1_ls1_std = np.std(b1_corrected_vs1)\n",
    "b2_ls1_std = np.std(b2_corrected_vs1)\n",
    "c1_ls1_std = np.std(c1_corrected_vs1)\n",
    "ls1_std_list = [a1_ls1_std, a2_ls1_std, b1_ls1_std, b2_ls1_std, c1_ls1_std]\n",
    "\n",
    "# Lexical Sophistication-II mean\n",
    "a1_ls2_mean = np.mean(a1_verb_sophistication_II)\n",
    "a2_ls2_mean = np.mean(a2_verb_sophistication_II)\n",
    "b1_ls2_mean = np.mean(b1_verb_sophistication_II)\n",
    "b2_ls2_mean = np.mean(b2_verb_sophistication_II)\n",
    "c1_ls2_mean = np.mean(c1_verb_sophistication_II)\n",
    "ls2_mean_list = [a1_ls2_mean, a2_ls2_mean, b1_ls2_mean, b2_ls2_mean, c1_ls2_mean]\n",
    "\n",
    "# Lexical Sophistication-II std\n",
    "a1_ls2_std = np.std(a1_verb_sophistication_II)\n",
    "a2_ls2_std = np.std(a2_verb_sophistication_II)\n",
    "b1_ls2_std = np.std(b1_verb_sophistication_II)\n",
    "b2_ls2_std = np.std(b2_verb_sophistication_II)\n",
    "c1_ls2_std = np.std(c1_verb_sophistication_II)\n",
    "ls2_std_list = [a1_ls2_std, a2_ls2_std, b1_ls2_std, b2_ls2_std, c1_ls2_std]\n",
    "\n",
    "# Verb Sophistication-I mean\n",
    "a1_vs1_mean = np.mean(a1_verb_variation_I)\n",
    "a2_vs1_mean = np.mean(a2_verb_variation_I)\n",
    "b1_vs1_mean = np.mean(b1_verb_variation_I)\n",
    "b2_vs1_mean = np.mean(b2_verb_variation_I)\n",
    "c1_vs1_mean = np.mean(c1_verb_variation_I)\n",
    "vs1_mean_list = [a1_vs1_mean, a2_vs1_mean, b1_vs1_mean, b2_vs1_mean, c1_vs1_mean]\n",
    "\n",
    "# Verb Sophistication-I std\n",
    "a1_vs1_std = np.std(a1_verb_variation_I)\n",
    "a2_vs1_std = np.std(a2_verb_variation_I)\n",
    "b1_vs1_std = np.std(b1_verb_variation_I)\n",
    "b2_vs1_std = np.std(b2_verb_variation_I)\n",
    "c1_vs1_std = np.std(c1_verb_variation_I)\n",
    "vs1_std_list = [a1_vs1_std, a2_vs1_std, b1_vs1_std, b2_vs1_std, c1_vs1_std]\n",
    "\n",
    "# Corrected VS1 mean\n",
    "a1_corrected_vs1_mean = np.mean(a1_corrected_vs1)\n",
    "a2_corrected_vs1_mean = np.mean(a2_corrected_vs1)\n",
    "b1_corrected_vs1_mean = np.mean(b1_corrected_vs1)\n",
    "b2_corrected_vs1_mean = np.mean(b2_corrected_vs1)\n",
    "c1_corrected_vs1_mean = np.mean(c1_corrected_vs1)\n",
    "corrected_vs1_mean_list = [a1_corrected_vs1_mean, a2_corrected_vs1_mean, b1_corrected_vs1_mean, b2_corrected_vs1_mean, c1_corrected_vs1_mean]\n",
    "\n",
    "# Corrected VS1 std\n",
    "a1_corrected_vs1_std = np.std(a1_corrected_vs1)\n",
    "a2_corrected_vs1_std = np.std(a2_corrected_vs1)\n",
    "b1_corrected_vs1_std = np.std(b1_corrected_vs1)\n",
    "b2_corrected_vs1_std = np.std(b2_corrected_vs1)\n",
    "c1_corrected_vs1_std = np.std(c1_corrected_vs1)\n",
    "corrected_vs1_std_list = [a1_corrected_vs1_std, a2_corrected_vs1_std, b1_corrected_vs1_std, b2_corrected_vs1_std, c1_corrected_vs1_std]\n",
    "\n",
    "# Verb Sophistication-II mean\n",
    "a1_vs2_mean = np.mean(a1_verb_variation_II)\n",
    "a2_vs2_mean = np.mean(a2_verb_variation_II)\n",
    "b1_vs2_mean = np.mean(b1_verb_variation_II)\n",
    "b2_vs2_mean = np.mean(b2_verb_variation_II)\n",
    "c1_vs2_mean = np.mean(c1_verb_variation_II)\n",
    "vs2_mean_list = [a1_vs2_mean, a2_vs2_mean, b1_vs2_mean, b2_vs2_mean, c1_vs2_mean]\n",
    "\n",
    "# Verb Sophistication-II std\n",
    "a1_vs2_std = np.std(a1_verb_variation_II)\n",
    "a2_vs2_std = np.std(a2_verb_variation_II)\n",
    "b1_vs2_std = np.std(b1_verb_variation_II)\n",
    "b2_vs2_std = np.std(b2_verb_variation_II)\n",
    "c1_vs2_std = np.std(c1_verb_variation_II)\n",
    "vs2_std_list = [a1_vs2_std, a2_vs2_std, b1_vs2_std, b2_vs2_std, c1_vs2_std]\n",
    "\n",
    "# Number of Different Words mean\n",
    "a1_ndw_mean = np.mean(a1_number_of_different_words)\n",
    "a2_ndw_mean = np.mean(a2_number_of_different_words)\n",
    "b1_ndw_mean = np.mean(b1_number_of_different_words)\n",
    "b2_ndw_mean = np.mean(b2_number_of_different_words)\n",
    "c1_ndw_mean = np.mean(c1_number_of_different_words)\n",
    "ndw_mean_list = [a1_ndw_mean, a2_ndw_mean, b1_ndw_mean, b2_ndw_mean, c1_ndw_mean]\n",
    "\n",
    "# Number of Different Words std\n",
    "a1_ndw_std = np.std(a1_number_of_different_words)\n",
    "a2_ndw_std = np.std(a2_number_of_different_words)\n",
    "b1_ndw_std = np.std(b1_number_of_different_words)\n",
    "b2_ndw_std = np.std(b2_number_of_different_words)\n",
    "c1_ndw_std = np.std(c1_number_of_different_words)\n",
    "ndw_std_list = [a1_ndw_std, a2_ndw_std, b1_ndw_std, b2_ndw_std, c1_ndw_std]\n",
    "\n",
    "# Type-Token Ratio mean\n",
    "a1_ttr_mean = np.mean(a1_ttr)\n",
    "a2_ttr_mean = np.mean(a2_ttr)\n",
    "b1_ttr_mean = np.mean(b1_ttr)\n",
    "b2_ttr_mean = np.mean(b2_ttr)\n",
    "c1_ttr_mean = np.mean(c1_ttr)\n",
    "ttr_mean_list = [a1_ttr_mean, a2_ttr_mean, b1_ttr_mean, b2_ttr_mean, c1_ttr_mean]\n",
    "\n",
    "# Type-Token Ratio std\n",
    "a1_ttr_std = np.std(a1_ttr)\n",
    "a2_ttr_std = np.std(a2_ttr)\n",
    "b1_ttr_std = np.std(b1_ttr)\n",
    "b2_ttr_std = np.std(b2_ttr)\n",
    "c1_ttr_std = np.std(c1_ttr)\n",
    "ttr_std_list = [a1_ttr_std, a2_ttr_std, b1_ttr_std, b2_ttr_std, c1_ttr_std]\n",
    "\n",
    "\n",
    "# Corrected TTR mean\n",
    "\n",
    "a1_corrected_ttr_mean = np.mean(a1_corrected_ttr)\n",
    "a2_corrected_ttr_mean = np.mean(a2_corrected_ttr)\n",
    "b1_corrected_ttr_mean = np.mean(b1_corrected_ttr)\n",
    "b2_corrected_ttr_mean = np.mean(b2_corrected_ttr)\n",
    "c1_corrected_ttr_mean = np.mean(c1_corrected_ttr)\n",
    "corrected_ttr_mean_list = [a1_corrected_ttr_mean, a2_corrected_ttr_mean, b1_corrected_ttr_mean, b2_corrected_ttr_mean, c1_corrected_ttr_mean]\n",
    "\n",
    "# Corrected TTR std\n",
    "\n",
    "a1_corrected_ttr_std = np.std(a1_corrected_ttr)\n",
    "a2_corrected_ttr_std = np.std(a2_corrected_ttr)\n",
    "b1_corrected_ttr_std = np.std(b1_corrected_ttr)\n",
    "b2_corrected_ttr_std = np.std(b2_corrected_ttr)\n",
    "c1_corrected_ttr_std = np.std(c1_corrected_ttr)\n",
    "corrected_ttr_std_list = [a1_corrected_ttr_std, a2_corrected_ttr_std, b1_corrected_ttr_std, b2_corrected_ttr_std, c1_corrected_ttr_std]\n",
    "\n",
    "# Root TTR mean\n",
    "a1_root_ttr_mean = np.mean(a1_root_ttr)\n",
    "a2_root_ttr_mean = np.mean(a2_root_ttr)\n",
    "b1_root_ttr_mean = np.mean(b1_root_ttr)\n",
    "b2_root_ttr_mean = np.mean(b2_root_ttr)\n",
    "c1_root_ttr_mean = np.mean(c1_root_ttr)\n",
    "root_ttr_mean_list = [a1_root_ttr_mean, a2_root_ttr_mean, b1_root_ttr_mean, b2_root_ttr_mean, c1_root_ttr_mean]\n",
    "\n",
    "# Root TTR std\n",
    "a1_root_ttr_std = np.std(a1_root_ttr)\n",
    "a2_root_ttr_std = np.std(a2_root_ttr)\n",
    "b1_root_ttr_std = np.std(b1_root_ttr)\n",
    "b2_root_ttr_std = np.std(b2_root_ttr)\n",
    "c1_root_ttr_std = np.std(c1_root_ttr)\n",
    "root_ttr_std_list = [a1_root_ttr_std, a2_root_ttr_std, b1_root_ttr_std, b2_root_ttr_std, c1_root_ttr_std]\n",
    "\n",
    "# Bilogarithmic TTR mean\n",
    "a1_bilog_ttr_mean = np.mean(a1_bilogarithmic_ttr)\n",
    "a2_bilog_ttr_mean = np.mean(a2_bilogarithmic_ttr)\n",
    "b1_bilog_ttr_mean = np.mean(b1_bilogarithmic_ttr)\n",
    "b2_bilog_ttr_mean = np.mean(b2_bilogarithmic_ttr)\n",
    "c1_bilog_ttr_mean = np.mean(c1_bilogarithmic_ttr)\n",
    "bilog_ttr_mean_list = [a1_bilog_ttr_mean, a2_bilog_ttr_mean, b1_bilog_ttr_mean, b2_bilog_ttr_mean, c1_bilog_ttr_mean]\n",
    "\n",
    "# Bilogarithmic TTR std\n",
    "a1_bilog_ttr_std = np.std(a1_bilogarithmic_ttr)\n",
    "a2_bilog_ttr_std = np.std(a2_bilogarithmic_ttr)\n",
    "b1_bilog_ttr_std = np.std(b1_bilogarithmic_ttr)\n",
    "b2_bilog_ttr_std = np.std(b2_bilogarithmic_ttr)\n",
    "c1_bilog_ttr_std = np.std(c1_bilogarithmic_ttr)\n",
    "bilog_ttr_std_list = [a1_bilog_ttr_std, a2_bilog_ttr_std, b1_bilog_ttr_std, b2_bilog_ttr_std, c1_bilog_ttr_std]\n",
    "\n",
    "# Uber Index mean\n",
    "a1_uber_index_mean = np.mean(a1_uber_index)\n",
    "a2_uber_index_mean = np.mean(a2_uber_index)\n",
    "b1_uber_index_mean = np.mean(b1_uber_index)\n",
    "b2_uber_index_mean = np.mean(b2_uber_index)\n",
    "c1_uber_index_mean = np.mean(c1_uber_index)\n",
    "uber_index_mean_list = [a1_uber_index_mean, a2_uber_index_mean, b1_uber_index_mean, b2_uber_index_mean, c1_uber_index_mean]\n",
    "\n",
    "# Uber Index std\n",
    "a1_uber_index_std = np.std(a1_uber_index)\n",
    "a2_uber_index_std = np.std(a2_uber_index)\n",
    "b1_uber_index_std = np.std(b1_uber_index)\n",
    "b2_uber_index_std = np.std(b2_uber_index)\n",
    "c1_uber_index_std = np.std(c1_uber_index)\n",
    "uber_index_std_list = [a1_uber_index_std, a2_uber_index_std, b1_uber_index_std, b2_uber_index_std, c1_uber_index_std]\n",
    "\n",
    "# Lexical Word Variation mean\n",
    "a1_lwv_mean = np.mean(a1_lexical_word_variation)\n",
    "a2_lwv_mean = np.mean(a2_lexical_word_variation)\n",
    "b1_lwv_mean = np.mean(b1_lexical_word_variation)\n",
    "b2_lwv_mean = np.mean(b2_lexical_word_variation)\n",
    "c1_lwv_mean = np.mean(c1_lexical_word_variation)\n",
    "lwv_mean_list = [a1_lwv_mean, a2_lwv_mean, b1_lwv_mean, b2_lwv_mean, c1_lwv_mean]\n",
    "\n",
    "# Lexical Word Variation std\n",
    "a1_lwv_std = np.std(a1_lexical_word_variation)\n",
    "a2_lwv_std = np.std(a2_lexical_word_variation)\n",
    "b1_lwv_std = np.std(b1_lexical_word_variation)\n",
    "b2_lwv_std = np.std(b2_lexical_word_variation)\n",
    "c1_lwv_std = np.std(c1_lexical_word_variation)\n",
    "lwv_std_list = [a1_lwv_std, a2_lwv_std, b1_lwv_std, b2_lwv_std, c1_lwv_std]\n",
    "\n",
    "# Verb Variation-I mean\n",
    "a1_vv1_mean = np.mean(a1_verb_variation_I)\n",
    "a2_vv1_mean = np.mean(a2_verb_variation_I)\n",
    "b1_vv1_mean = np.mean(b1_verb_variation_I)\n",
    "b2_vv1_mean = np.mean(b2_verb_variation_I)\n",
    "c1_vv1_mean = np.mean(c1_verb_variation_I)\n",
    "vv1_mean_list = [a1_vv1_mean, a2_vv1_mean, b1_vv1_mean, b2_vv1_mean, c1_vv1_mean]\n",
    "\n",
    "# Verb Variation-I std\n",
    "a1_vv1_std = np.std(a1_verb_variation_I)\n",
    "a2_vv1_std = np.std(a2_verb_variation_I)\n",
    "b1_vv1_std = np.std(b1_verb_variation_I)\n",
    "b2_vv1_std = np.std(b2_verb_variation_I)\n",
    "c1_vv1_std = np.std(c1_verb_variation_I)\n",
    "vv1_std_list = [a1_vv1_std, a2_vv1_std, b1_vv1_std, b2_vv1_std, c1_vv1_std]\n",
    "\n",
    "# Squared VV1 mean\n",
    "a1_sq_vv1_mean = np.mean(a1_squared_vv1)\n",
    "a2_sq_vv1_mean = np.mean(a2_squared_vv1)\n",
    "b1_sq_vv1_mean = np.mean(b1_squared_vv1)\n",
    "b2_sq_vv1_mean = np.mean(b2_squared_vv1)\n",
    "c1_sq_vv1_mean = np.mean(c1_squared_vv1)\n",
    "sq_vv1_mean_list = [a1_sq_vv1_mean, a2_sq_vv1_mean, b1_sq_vv1_mean, b2_sq_vv1_mean, c1_sq_vv1_mean]\n",
    "\n",
    "# Squared VV1 std\n",
    "a1_sq_vv1_std = np.std(a1_squared_vv1)\n",
    "a2_sq_vv1_std = np.std(a2_squared_vv1)\n",
    "b1_sq_vv1_std = np.std(b1_squared_vv1)\n",
    "b2_sq_vv1_std = np.std(b2_squared_vv1)\n",
    "c1_sq_vv1_std = np.std(c1_squared_vv1)\n",
    "sq_vv1_std_list = [a1_sq_vv1_std, a2_sq_vv1_std, b1_sq_vv1_std, b2_sq_vv1_std, c1_sq_vv1_std]\n",
    "\n",
    "# Corrected VV1 mean\n",
    "a1_cvv1_mean = np.mean(a1_corrected_vv1)\n",
    "a2_cvv1_mean = np.mean(a2_corrected_vv1)\n",
    "b1_cvv1_mean = np.mean(b1_corrected_vv1)\n",
    "b2_cvv1_mean = np.mean(b2_corrected_vv1)\n",
    "c1_cvv1_mean = np.mean(c1_corrected_vv1)\n",
    "cvv1_mean_list = [a1_cvv1_mean, a2_cvv1_mean, b1_cvv1_mean, b2_cvv1_mean, c1_cvv1_mean]\n",
    "\n",
    "# Corrected VV1 std\n",
    "a1_cvv1_std = np.std(a1_corrected_vv1)\n",
    "a2_cvv1_std = np.std(a2_corrected_vv1)\n",
    "b1_cvv1_std = np.std(b1_corrected_vv1)\n",
    "b2_cvv1_std = np.std(b2_corrected_vv1)\n",
    "c1_cvv1_std = np.std(c1_corrected_vv1)\n",
    "cvv1_std_list = [a1_cvv1_std, a2_cvv1_std, b1_cvv1_std, b2_cvv1_std, c1_cvv1_std]\n",
    "\n",
    "# Verb Variation-II mean\n",
    "a1_vv2_mean = np.mean(a1_verb_variation_II)\n",
    "a2_vv2_mean = np.mean(a2_verb_variation_II)\n",
    "b1_vv2_mean = np.mean(b1_verb_variation_II)\n",
    "b2_vv2_mean = np.mean(b2_verb_variation_II)\n",
    "c1_vv2_mean = np.mean(c1_verb_variation_II)\n",
    "vv2_mean_list = [a1_vv2_mean, a2_vv2_mean, b1_vv2_mean, b2_vv2_mean, c1_vv2_mean]\n",
    "\n",
    "# Verb Variation-II std\n",
    "a1_vv2_std = np.std(a1_verb_variation_II)\n",
    "a2_vv2_std = np.std(a2_verb_variation_II)\n",
    "b1_vv2_std = np.std(b1_verb_variation_II)\n",
    "b2_vv2_std = np.std(b2_verb_variation_II)\n",
    "c1_vv2_std = np.std(c1_verb_variation_II)\n",
    "vv2_std_list = [a1_vv2_std, a2_vv2_std, b1_vv2_std, b2_vv2_std, c1_vv2_std]\n",
    "\n",
    "# Noun Variation mean\n",
    "a1_nv_mean = np.mean(a1_noun_variation)\n",
    "a2_nv_mean = np.mean(a2_noun_variation)\n",
    "b1_nv_mean = np.mean(b1_noun_variation)\n",
    "b2_nv_mean = np.mean(b2_noun_variation)\n",
    "c1_nv_mean = np.mean(c1_noun_variation)\n",
    "nv_mean_list = [a1_nv_mean, a2_nv_mean, b1_nv_mean, b2_nv_mean, c1_nv_mean]\n",
    "\n",
    "# Noun Variation std\n",
    "a1_nv_std = np.std(a1_noun_variation)\n",
    "a2_nv_std = np.std(a2_noun_variation)\n",
    "b1_nv_std = np.std(b1_noun_variation)\n",
    "b2_nv_std = np.std(b2_noun_variation)\n",
    "c1_nv_std = np.std(c1_noun_variation)\n",
    "nv_std_list = [a1_nv_std, a2_nv_std, b1_nv_std, b2_nv_std, c1_nv_std]\n",
    "\n",
    "# Adjective Variation mean\n",
    "a1_av_mean = np.mean(a1_adjective_variation)\n",
    "a2_av_mean = np.mean(a2_adjective_variation)\n",
    "b1_av_mean = np.mean(b1_adjective_variation)\n",
    "b2_av_mean = np.mean(b2_adjective_variation)\n",
    "c1_av_mean = np.mean(c1_adjective_variation)\n",
    "av_mean_list = [a1_av_mean, a2_av_mean, b1_av_mean, b2_av_mean, c1_av_mean]\n",
    "\n",
    "# Adjective Variation std\n",
    "a1_av_std = np.std(a1_adjective_variation)\n",
    "a2_av_std = np.std(a2_adjective_variation)\n",
    "b1_av_std = np.std(b1_adjective_variation)\n",
    "b2_av_std = np.std(b2_adjective_variation)\n",
    "c1_av_std = np.std(c1_adjective_variation)\n",
    "av_std_list = [a1_av_std, a2_av_std, b1_av_std, b2_av_std, c1_av_std]\n",
    "\n",
    "# Adverb Variation mean\n",
    "a1_adv_mean = np.mean(a1_adverb_variation)\n",
    "a2_adv_mean = np.mean(a2_adverb_variation)\n",
    "b1_adv_mean = np.mean(b1_adverb_variation)\n",
    "b2_adv_mean = np.mean(b2_adverb_variation)\n",
    "c1_adv_mean = np.mean(c1_adverb_variation)\n",
    "adv_mean_list = [a1_adv_mean, a2_adv_mean, b1_adv_mean, b2_adv_mean, c1_adv_mean]\n",
    "\n",
    "# Adverb Variation std\n",
    "a1_adv_std = np.std(a1_adverb_variation)\n",
    "a2_adv_std = np.std(a2_adverb_variation)\n",
    "b1_adv_std = np.std(b1_adverb_variation)\n",
    "b2_adv_std = np.std(b2_adverb_variation)\n",
    "c1_adv_std = np.std(c1_adverb_variation)\n",
    "adv_std_list = [a1_adv_std, a2_adv_std, b1_adv_std, b2_adv_std, c1_adv_std]\n",
    "\n",
    "# Modifier Variation mean\n",
    "a1_mod_mean = np.mean(a1_modifier_variation)\n",
    "a2_mod_mean = np.mean(a2_modifier_variation)\n",
    "b1_mod_mean = np.mean(b1_modifier_variation)\n",
    "b2_mod_mean = np.mean(b2_modifier_variation)\n",
    "c1_mod_mean = np.mean(c1_modifier_variation)\n",
    "mod_mean_list = [a1_mod_mean, a2_mod_mean, b1_mod_mean, b2_mod_mean, c1_mod_mean]\n",
    "\n",
    "# Modifier Variation std\n",
    "a1_mod_std = np.std(a1_modifier_variation)\n",
    "a2_mod_std = np.std(a2_modifier_variation)\n",
    "b1_mod_std = np.std(b1_modifier_variation)\n",
    "b2_mod_std = np.std(b2_modifier_variation)\n",
    "c1_mod_std = np.std(c1_modifier_variation)\n",
    "mod_std_list = [a1_mod_std, a2_mod_std, b1_mod_std, b2_mod_std, c1_mod_std]\n",
    "\n",
    "# Maas TTR mean\n",
    "a1_maas_ttr_mean = np.mean(a1_maas_ttr)\n",
    "a2_maas_ttr_mean = np.mean(a2_maas_ttr)\n",
    "b1_maas_ttr_mean = np.mean(b1_maas_ttr)\n",
    "b2_maas_ttr_mean = np.mean(b2_maas_ttr)\n",
    "c1_maas_ttr_mean = np.mean(c1_maas_ttr)\n",
    "maas_ttr_mean_list = [a1_maas_ttr_mean, a2_maas_ttr_mean, b1_maas_ttr_mean, b2_maas_ttr_mean, c1_maas_ttr_mean]\n",
    "\n",
    "# Maas TTR std\n",
    "a1_maas_ttr_std = np.std(a1_maas_ttr)\n",
    "a2_maas_ttr_std = np.std(a2_maas_ttr)\n",
    "b1_maas_ttr_std = np.std(b1_maas_ttr)\n",
    "b2_maas_ttr_std = np.std(b2_maas_ttr)\n",
    "c1_maas_ttr_std = np.std(c1_maas_ttr)\n",
    "maas_ttr_std_list = [a1_maas_ttr_std, a2_maas_ttr_std, b1_maas_ttr_std, b2_maas_ttr_std, c1_maas_ttr_std]\n",
    "\n",
    "# HDD mean\n",
    "a1_hdd_mean = np.mean(a1_hdd)\n",
    "a2_hdd_mean = np.mean(a2_hdd)\n",
    "b1_hdd_mean = np.mean(b1_hdd)\n",
    "b2_hdd_mean = np.mean(b2_hdd)\n",
    "c1_hdd_mean = np.mean(c1_hdd)\n",
    "hdd_mean_list = [a1_hdd_mean, a2_hdd_mean, b1_hdd_mean, b2_hdd_mean, c1_hdd_mean]\n",
    "\n",
    "# HDD std\n",
    "a1_hdd_std = np.std(a1_hdd)\n",
    "a2_hdd_std = np.std(a2_hdd)\n",
    "b1_hdd_std = np.std(b1_hdd)\n",
    "b2_hdd_std = np.std(b2_hdd)\n",
    "c1_hdd_std = np.std(c1_hdd)\n",
    "hdd_std_list = [a1_hdd_std, a2_hdd_std, b1_hdd_std, b2_hdd_std, c1_hdd_std]\n",
    "\n",
    "# MTLD mean\n",
    "a1_mtld_mean = np.mean(a1_mtld)\n",
    "a2_mtld_mean = np.mean(a2_mtld)\n",
    "b1_mtld_mean = np.mean(b1_mtld)\n",
    "b2_mtld_mean = np.mean(b2_mtld)\n",
    "c1_mtld_mean = np.mean(c1_mtld)\n",
    "mtld_mean_list = [a1_mtld_mean, a2_mtld_mean, b1_mtld_mean, b2_mtld_mean, c1_mtld_mean]\n",
    "\n",
    "# MTLD std\n",
    "a1_mtld_std = np.std(a1_mtld)\n",
    "a2_mtld_std = np.std(a2_mtld)\n",
    "b1_mtld_std = np.std(b1_mtld)\n",
    "b2_mtld_std = np.std(b2_mtld)\n",
    "c1_mtld_std = np.std(c1_mtld)\n",
    "mtld_std_list = [a1_mtld_std, a2_mtld_std, b1_mtld_std, b2_mtld_std, c1_mtld_std]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fe77fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.087784785708347"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means_corrected_ttr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8efda58d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8364594648959796"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_corrected_ttr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1c400ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Lexical Density'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Lexical Density'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#all index mean\u001b[39;00m\n\u001b[1;32m      9\u001b[0m mean_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 11\u001b[0m mean_list\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLexical Density\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m     12\u001b[0m mean_list\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLexical Sophistication-I\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m     13\u001b[0m mean_list\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLexical Sophistication-II\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Lexical Density'"
     ]
    }
   ],
   "source": [
    "#all index name\n",
    "index_name = [\"Lexical Density\",\"Lexical Sophistication-I\",\"Lexical Sophistication-II\",\"Verb Sophistication-I\",\"Corrected VS1\",\"Verb Sophistication-II\",\"Number of Different Words\",\"Type–Token Ratio\",\"Corrected TTR\",\"Root TTR\",\"Bilogarithmic TTR\",\"Uber Index\",\"Lexical Word Variation\",\n",
    "\"Verb Variation-I\",\"Squared VV1\",\"Corrected VV1\",\"Verb Variation-II\",\"Noun Variation\",\"Adjective Variation\",\"Adverb Variation\",\"Modifier Variation\",\"Maas_TTR\",\"HDD\",\"MTLD\"\n",
    "]\n",
    "\n",
    "\n",
    "#all index mean\n",
    "\n",
    "mean_list = []\n",
    "\n",
    "mean_list.append(np.mean(df[\"Lexical Density\"]))\n",
    "mean_list.append(np.mean(df[\"Lexical Sophistication-I\"]))\n",
    "mean_list.append(np.mean(df[\"Lexical Sophistication-II\"]))\n",
    "mean_list.append(np.mean(df[\"Verb Sophistication-I\"]))\n",
    "mean_list.append(np.mean(df[\"Corrected VS1\"]))\n",
    "mean_list.append(np.mean(df[\"Verb Sophistication-II\"]))\n",
    "mean_list.append(np.mean(df[\"Number of Different Words\"]))\n",
    "mean_list.append(np.mean(df[\"Type–Token Ratio\"]))\n",
    "mean_list.append(np.mean(df[\"Corrected TTR\"]))\n",
    "mean_list.append(np.mean(df[\"Root TTR\"]))\n",
    "mean_list.append(np.mean(df[\"Bilogarithmic TTR\"]))\n",
    "mean_list.append(np.mean(df[\"Uber Index\"]))\n",
    "mean_list.append(np.mean(df[\"Lexical Word Variation\"]))\n",
    "mean_list.append(np.mean(df[\"Verb Variation-I\"]))\n",
    "mean_list.append(np.mean(df[\"Squared VV1\"]))\n",
    "mean_list.append(np.mean(df[\"Corrected VV1\"]))\n",
    "mean_list.append(np.mean(df[\"Verb Variation-II\"]))\n",
    "mean_list.append(np.mean(df[\"Noun Variation\"]))\n",
    "mean_list.append(np.mean(df[\"Adjective Variation\"]))\n",
    "mean_list.append(np.mean(df[\"Adverb Variation\"]))\n",
    "mean_list.append(np.mean(df[\"Modifier Variation\"]))\n",
    "mean_list.append(np.mean(df[\"Maas_TTR\"]))\n",
    "mean_list.append(np.mean(df[\"HDD\"]))\n",
    "mean_list.append(np.mean(df[\"MTLD\"]))\n",
    "\n",
    "# all index std\n",
    "\n",
    "std_list = []\n",
    "\n",
    "std_list.append(np.std(df[\"Lexical Density\"]))\n",
    "std_list.append(np.std(df[\"Lexical Sophistication-I\"]))\n",
    "std_list.append(np.std(df[\"Lexical Sophistication-II\"]))\n",
    "std_list.append(np.std(df[\"Verb Sophistication-I\"]))\n",
    "std_list.append(np.std(df[\"Corrected VS1\"]))\n",
    "std_list.append(np.std(df[\"Verb Sophistication-II\"]))\n",
    "std_list.append(np.std(df[\"Number of Different Words\"]))\n",
    "std_list.append(np.std(df[\"Type–Token Ratio\"]))\n",
    "std_list.append(np.std(df[\"Corrected TTR\"]))\n",
    "std_list.append(np.std(df[\"Root TTR\"]))\n",
    "std_list.append(np.std(df[\"Bilogarithmic TTR\"]))\n",
    "std_list.append(np.std(df[\"Uber Index\"]))\n",
    "std_list.append(np.std(df[\"Lexical Word Variation\"]))\n",
    "std_list.append(np.std(df[\"Verb Variation-I\"]))\n",
    "std_list.append(np.std(df[\"Squared VV1\"]))\n",
    "std_list.append(np.std(df[\"Corrected VV1\"]))\n",
    "std_list.append(np.std(df[\"Verb Variation-II\"]))\n",
    "std_list.append(np.std(df[\"Noun Variation\"]))\n",
    "std_list.append(np.std(df[\"Adjective Variation\"]))\n",
    "std_list.append(np.std(df[\"Adverb Variation\"]))\n",
    "std_list.append(np.std(df[\"Modifier Variation\"]))\n",
    "std_list.append(np.std(df[\"Maas_TTR\"]))\n",
    "std_list.append(np.std(df[\"HDD\"]))\n",
    "std_list.append(np.std(df[\"MTLD\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6753cd91",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'index_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m index_final_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVariable\u001b[39m\u001b[38;5;124m\"\u001b[39m:index_name,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m\"\u001b[39m:[\u001b[38;5;241m406062.0\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m24\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean\u001b[39m\u001b[38;5;124m\"\u001b[39m:mean_list,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSD\u001b[39m\u001b[38;5;124m\"\u001b[39m:std_list})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'index_name' is not defined"
     ]
    }
   ],
   "source": [
    "index_final_data = pd.DataFrame({\"Variable\":index_name,\"N\":[406062.0]*24,\"Mean\":mean_list,\"SD\":std_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "948db510",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'index_final_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m index_final_data\u001b[38;5;241m.\u001b[39mto_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m測試.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'index_final_data' is not defined"
     ]
    }
   ],
   "source": [
    "index_final_data.to_excel('測試.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a27e60b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nums_a1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Lexical Density DataFrame\u001b[39;00m\n\u001b[1;32m      2\u001b[0m ld_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCEFR\u001b[39m\u001b[38;5;124m\"\u001b[39m:[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC1\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m----> 3\u001b[0m                                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m\"\u001b[39m:[nums_a1,nums_a2,nums_b1,nums_b2,nums_c1],\n\u001b[1;32m      4\u001b[0m                                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean\u001b[39m\u001b[38;5;124m\"\u001b[39m:ld_mean_list,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSD\u001b[39m\u001b[38;5;124m\"\u001b[39m:ld_std_list})\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Lexical Sophistication-I DataFrame\u001b[39;00m\n\u001b[1;32m      7\u001b[0m ls1_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCEFR\u001b[39m\u001b[38;5;124m\"\u001b[39m:[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC1\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      8\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m\"\u001b[39m:[nums_a1, nums_a2, nums_b1, nums_b2, nums_c1],\n\u001b[1;32m      9\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean\u001b[39m\u001b[38;5;124m\"\u001b[39m:ls1_mean_list,\n\u001b[1;32m     10\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSD\u001b[39m\u001b[38;5;124m\"\u001b[39m:ls1_std_list})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nums_a1' is not defined"
     ]
    }
   ],
   "source": [
    "# Lexical Density DataFrame\n",
    "ld_df = pd.DataFrame({\"CEFR\":[\"A1\",\"A2\",\"B1\",\"B2\",\"C1\"],\n",
    "                                   \"N\":[nums_a1,nums_a2,nums_b1,nums_b2,nums_c1],\n",
    "                                   \"Mean\":ld_mean_list,\"SD\":ld_std_list})\n",
    "\n",
    "# Lexical Sophistication-I DataFrame\n",
    "ls1_df = pd.DataFrame({\"CEFR\":[\"A1\",\"A2\",\"B1\",\"B2\",\"C1\"],\n",
    "                       \"N\":[nums_a1, nums_a2, nums_b1, nums_b2, nums_c1],\n",
    "                       \"Mean\":ls1_mean_list,\n",
    "                       \"SD\":ls1_std_list})\n",
    "\n",
    "# Lexical Sophistication-II DataFrame\n",
    "ls2_df = pd.DataFrame({\"CEFR\":[\"A1\",\"A2\",\"B1\",\"B2\",\"C1\"],\n",
    "                       \"N\":[nums_a1, nums_a2, nums_b1, nums_b2, nums_c1],\n",
    "                       \"Mean\":ls2_mean_list,\n",
    "                       \"SD\":ls2_std_list})\n",
    "\n",
    "# Verb Sophistication-I DataFrame\n",
    "vs1_df = pd.DataFrame({\"CEFR\":[\"A1\",\"A2\",\"B1\",\"B2\",\"C1\"],\n",
    "                       \"N\":[nums_a1, nums_a2, nums_b1, nums_b2, nums_c1],\n",
    "                       \"Mean\":vs1_mean_list,\n",
    "                       \"SD\":vs1_std_list})\n",
    "\n",
    "# Corrected VS1 DataFrame\n",
    "corrected_vs1_df = pd.DataFrame({\"CEFR\":[\"A1\",\"A2\",\"B1\",\"B2\",\"C1\"],\n",
    "                       \"N\":[nums_a1, nums_a2, nums_b1, nums_b2, nums_c1],\n",
    "                       \"Mean\":corrected_vs1_mean_list,\n",
    "                       \"SD\":corrected_vs1_std_list})\n",
    "\n",
    "# Verb Sophistication-II DataFrame\n",
    "vs2_df = pd.DataFrame({\"CEFR\":[\"A1\",\"A2\",\"B1\",\"B2\",\"C1\"],\n",
    "                       \"N\":[nums_a1, nums_a2, nums_b1, nums_b2, nums_c1],\n",
    "                       \"Mean\":vs2_mean_list,\n",
    "                       \"SD\":vs2_std_list})\n",
    "\n",
    "# Number of Different Words DataFrame\n",
    "ndw_df = pd.DataFrame({\"CEFR\":[\"A1\",\"A2\",\"B1\",\"B2\",\"C1\"],\n",
    "                       \"N\":[nums_a1, nums_a2, nums_b1, nums_b2, nums_c1],\n",
    "                       \"Mean\":ndw_mean_list,\n",
    "                       \"SD\":ndw_std_list})\n",
    "\n",
    "# Corrected TTR Ratio DataFrame\n",
    "corrected_ttr_df = pd.DataFrame({\"CEFR\":[\"A1\",\"A2\",\"B1\",\"B2\",\"C1\"],\n",
    "                       \"N\":[nums_a1, nums_a2, nums_b1, nums_b2, nums_c1],\n",
    "                       \"Mean\":corrected_ttr_mean_list,\n",
    "                       \"SD\":corrected_ttr_std_list})\n",
    "\n",
    "# Type-Token Ratio DataFrame\n",
    "ttr_df = pd.DataFrame({\"CEFR\":[\"A1\",\"A2\",\"B1\",\"B2\",\"C1\"],\n",
    "                       \"N\":[nums_a1, nums_a2, nums_b1, nums_b2, nums_c1],\n",
    "                       \"Mean\":ttr_mean_list,\n",
    "                       \"SD\":ttr_std_list})\n",
    "\n",
    "# Root TTR DataFrame\n",
    "root_ttr_df = pd.DataFrame({\"CEFR\":[\"A1\",\"A2\",\"B1\",\"B2\",\"C1\"],\n",
    "                       \"N\":[nums_a1, nums_a2, nums_b1, nums_b2, nums_c1],\n",
    "                       \"Mean\":root_ttr_mean_list,\n",
    "                       \"SD\":root_ttr_std_list})\n",
    "\n",
    "# Bilogarithmic TTR DataFrame\n",
    "bilog_ttr_df = pd.DataFrame({\"CEFR\":[\"A1\",\"A2\",\"B1\",\"B2\",\"C1\"],\n",
    "                       \"N\":[nums_a1, nums_a2, nums_b1, nums_b2, nums_c1],\n",
    "                       \"Mean\":bilog_ttr_mean_list,\n",
    "                       \"SD\":bilog_ttr_std_list})\n",
    "\n",
    "# Uber Index DataFrame\n",
    "uber_index_df = pd.DataFrame({\"CEFR\":[\"A1\",\"A2\",\"B1\",\"B2\",\"C1\"],\n",
    "                       \"N\":[nums_a1, nums_a2, nums_b1, nums_b2, nums_c1],\n",
    "                       \"Mean\":uber_index_mean_list,\n",
    "                       \"SD\":uber_index_std_list})\n",
    "\n",
    "# Lexical Word Variation DataFrame\n",
    "lwv_df = pd.DataFrame({\"CEFR\":[\"A1\",\"A2\",\"B1\",\"B2\",\"C1\"],\n",
    "                       \"N\":[nums_a1, nums_a2, nums_b1, nums_b2, nums_c1],\n",
    "                       \"Mean\":lwv_mean_list,\n",
    "                       \"SD\":lwv_std_list})\n",
    "\n",
    "# Verb Variation-I DataFrame\n",
    "vv1_df = pd.DataFrame({\"CEFR\":[\"A1\",\"A2\",\"B1\",\"B2\",\"C1\"],\n",
    "                       \"N\":[nums_a1, nums_a2, nums_b1, nums_b2, nums_c1],\n",
    "                       \"Mean\":vv1_mean_list,\n",
    "                       \"SD\":vv1_std_list})\n",
    "\n",
    "# Squared VV1 DataFrame\n",
    "sq_vv1_df = pd.DataFrame({\"CEFR\":[\"A1\",\"A2\",\"B1\",\"B2\",\"C1\"],\n",
    "                       \"N\":[nums_a1, nums_a2, nums_b1, nums_b2, nums_c1],\n",
    "                       \"Mean\":sq_vv1_mean_list,\n",
    "                       \"SD\":sq_vv1_std_list})\n",
    "\n",
    "# Corrected VV1 DataFrame\n",
    "cvv1_df = pd.DataFrame({\"CEFR\":[\"A1\",\"A2\",\"B1\",\"B2\",\"C1\"],\n",
    "                       \"N\":[nums_a1, nums_a2, nums_b1, nums_b2, nums_c1],\n",
    "                       \"Mean\":cvv1_mean_list,\n",
    "                       \"SD\":cvv1_std_list})\n",
    "\n",
    "# Verb Variation-II DataFrame\n",
    "vv2_df = pd.DataFrame({\"CEFR\":[\"A1\",\"A2\",\"B1\",\"B2\",\"C1\"],\n",
    "                       \"N\":[nums_a1, nums_a2, nums_b1, nums_b2, nums_c1],\n",
    "                       \"Mean\":vv2_mean_list,\n",
    "                       \"SD\":vv2_std_list})\n",
    "\n",
    "# Noun Variation DataFrame\n",
    "nv_df = pd.DataFrame({\"CEFR\":[\"A1\",\"A2\",\"B1\",\"B2\",\"C1\"],\n",
    "                       \"N\":[nums_a1, nums_a2, nums_b1, nums_b2, nums_c1],\n",
    "                       \"Mean\":nv_mean_list,\n",
    "                       \"SD\":nv_std_list})\n",
    "\n",
    "# Adjective Variation DataFrame\n",
    "av_df = pd.DataFrame({\"CEFR\":[\"A1\",\"A2\",\"B1\",\"B2\",\"C1\"],\n",
    "                       \"N\":[nums_a1, nums_a2, nums_b1, nums_b2, nums_c1],\n",
    "                       \"Mean\":av_mean_list,\n",
    "                       \"SD\":av_std_list})\n",
    "\n",
    "# Adverb Variation DataFrame\n",
    "adv_df = pd.DataFrame({\"CEFR\":[\"A1\",\"A2\",\"B1\",\"B2\",\"C1\"],\n",
    "                       \"N\":[nums_a1, nums_a2, nums_b1, nums_b2, nums_c1],\n",
    "                       \"Mean\":adv_mean_list,\n",
    "                       \"SD\":adv_std_list})\n",
    "\n",
    "# Modifier Variation DataFrame\n",
    "mod_df = pd.DataFrame({\"CEFR\":[\"A1\",\"A2\",\"B1\",\"B2\",\"C1\"],\n",
    "                       \"N\":[nums_a1, nums_a2, nums_b1, nums_b2, nums_c1],\n",
    "                       \"Mean\":mod_mean_list,\n",
    "                       \"SD\":mod_std_list})\n",
    "\n",
    "# Maas TTR DataFrame\n",
    "maas_ttr_df = pd.DataFrame({\"CEFR\":[\"A1\",\"A2\",\"B1\",\"B2\",\"C1\"],\n",
    "                       \"N\":[nums_a1, nums_a2, nums_b1, nums_b2, nums_c1],\n",
    "                       \"Mean\":maas_ttr_mean_list,\n",
    "                       \"SD\":maas_ttr_std_list})\n",
    "\n",
    "# HDD DataFrame\n",
    "hdd_df = pd.DataFrame({\"CEFR\":[\"A1\",\"A2\",\"B1\",\"B2\",\"C1\"],\n",
    "                       \"N\":[nums_a1, nums_a2, nums_b1, nums_b2, nums_c1],\n",
    "                       \"Mean\":hdd_mean_list,\n",
    "                       \"SD\":hdd_std_list})\n",
    "\n",
    "# MTLD DataFrame\n",
    "mtld_df = pd.DataFrame({\"CEFR\":[\"A1\",\"A2\",\"B1\",\"B2\",\"C1\"],\n",
    "                       \"N\":[nums_a1, nums_a2, nums_b1, nums_b2, nums_c1],\n",
    "                       \"Mean\":mtld_mean_list,\n",
    "                       \"SD\":mtld_std_list})\n",
    "                         \n",
    "                                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ab78f32",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corrected_ttr_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m corrected_ttr_df\n",
      "\u001b[0;31mNameError\u001b[0m: name 'corrected_ttr_df' is not defined"
     ]
    }
   ],
   "source": [
    "corrected_ttr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce930dec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ttr_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ttr_df\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ttr_df' is not defined"
     ]
    }
   ],
   "source": [
    "ttr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8f12e1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建一個 Excel 寫入器\n",
    "with pd.ExcelWriter('output.xlsx') as writer:\n",
    "    # 將 DataFrame 寫入 Excel 文件\n",
    "    ld_df.to_excel(writer, sheet_name='Lexical Density', index=False)\n",
    "    ls1_df.to_excel(writer, sheet_name='Lexical_Sophistication_I', index=False)\n",
    "    ls2_df.to_excel(writer, sheet_name='Lexical_Sophistication_II', index=False)\n",
    "    vs1_df.to_excel(writer, sheet_name='Verb_Sophistication_I', index=False)\n",
    "    corrected_vs1_df.to_excel(writer, sheet_name='Corrected_Verb_Sophistication_I', index=False)\n",
    "    vs2_df.to_excel(writer, sheet_name='Verb_Sophistication_II', index=False)\n",
    "    ndw_df.to_excel(writer, sheet_name='Number_of_Different_Words', index=False)\n",
    "    ttr_df.to_excel(writer, sheet_name='Type-Token_Ratio', index=False)\n",
    "    root_ttr_df.to_excel(writer, sheet_name='Root_TTR', index=False)\n",
    "    bilog_ttr_df.to_excel(writer, sheet_name='Bilogarithmic_TTR', index=False)\n",
    "    uber_index_df.to_excel(writer, sheet_name='Uber_Index', index=False)\n",
    "    lwv_df.to_excel(writer, sheet_name='Lexical_Word_Variation', index=False)\n",
    "    vv1_df.to_excel(writer, sheet_name='Verb_Variation_I', index=False)\n",
    "    sq_vv1_df.to_excel(writer, sheet_name='Squared_Verb_Variation_I', index=False)\n",
    "    cvv1_df.to_excel(writer, sheet_name='Corrected_Verb_Variation_I', index=False)\n",
    "    vv2_df.to_excel(writer, sheet_name='Verb_Variation_II', index=False)\n",
    "    nv_df.to_excel(writer, sheet_name='Noun_Variation', index=False)\n",
    "    av_df.to_excel(writer, sheet_name='Adjective_Variation', index=False)\n",
    "    adv_df.to_excel(writer, sheet_name='Adverb_Variation', index=False)\n",
    "    mod_df.to_excel(writer, sheet_name='Modifier_Variation', index=False)\n",
    "    maas_ttr_df.to_excel(writer, sheet_name='Maas_TTR', index=False)\n",
    "    hdd_df.to_excel(writer, sheet_name='HDD', index=False)\n",
    "    mtld_df.to_excel(writer, sheet_name='MTLD', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b5066d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
